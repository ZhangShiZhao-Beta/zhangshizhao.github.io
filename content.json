{"meta":{"title":"SteveBlog","subtitle":"","description":"","author":"Steve Zhang","url":"http://example.com","root":"/"},"pages":[],"posts":[{"title":"OpenMp Simple Directives","slug":"OpenMp-Simple-Directives","date":"2024-12-13T05:40:01.000Z","updated":"2024-12-13T07:22:27.413Z","comments":true,"path":"2024/12/13/OpenMp-Simple-Directives/","permalink":"http://example.com/2024/12/13/OpenMp-Simple-Directives/","excerpt":"","text":"Normal dircetives 块并行指令 1. #pragma omp parallel定义Define a parallel region. 多个线程执行同一代码块 用法1234#pragma omp parallel&#123; xxxxx&#125; 原理 创建多线程，执行同一代码块当程序遇到 #pragma omp parallel 时，OpenMP 会创建多个线程来执行该代码块，默认情况下每个线程将执行相同的代码。线程的数量可以通过设置环境变量或在指令中明确指定。 2. #pragma omp parallel sections &amp; #pragma omp section定义分段协同工作结构（sections work-sharing construct），使用pragma omp section讲整个程序任务并行分割，openMp指定每个任务给不同的线程。 问题：分割数量超过线程数怎么办？ 答：OpenMP 会通过动态分配线程的方式来处理这些 section 用法12345678910111213141516171819202122#pragma omp parallel sections &#123;#pragma omp section &#123; xxx &#125;#pragma omp section &#123; xxx &#125;#pragma omp section &#123; xxx &#125;#pragma omp section &#123; xxx &#125; &#125; 原理 并行执行parallel sections中的section代码块，不在section块中的代码，不在本块内并行（除非被包含到更大的并行块中）。最好不要写在parallel sectionsd但不在section中的代码块，不同编译器实现不同创建线程池，分别执行程序员手动划分的代码块。程序会根据omp parallel sections中的section代码块进行分析，parallel section不是只允许有section代码块，omp会创建线程池去执行section块，只有用 #pragma omp section 标记的代码块才会被分配到不同的线程并行执行。不同的编译器实现有不同的表现，msvc不允许在section代码块后再添加非section代码块，gcc则可以。 3. #pragma omp single定义 用于指定某段代码仅由一个线程执行，而其他线程会在这一点上等待，这里具有一个隐式屏障。 如果不需要同步，可以用 nowait 修饰符移除隐式屏障。 #pragma omp single nowait 隐式屏障：等待点，所有线程执行完，再继续往后 OpenMP 中，当一个线程完成 #pragma omp single 代码块的执行后，所有线程会在这个代码块的末尾等待彼此，直到所有线程都到达这一点，然后再继续执行后续的代码。这种等待点被称为隐式屏障。 用法parallel中嵌套，用于线程间协调 123456789101112void ompSingle()&#123;#pragma omp parallel &#123;#pragma omp single &#123; std::cout &lt;&lt; &quot;Section thread: &quot; &lt;&lt; omp_get_thread_num() &lt;&lt; std::endl; &#125; std::cout &lt;&lt; &quot;Section thread: &quot; &lt;&lt; omp_get_thread_num() &lt;&lt; std::endl; &#125;&#125; 原理 线程选择、隐式屏障线程选择：择一线程执行。隐式屏障：single代码块结束有一屏障机制，确保同步后再执行。 4. #pragma omp parallel for定义创建一个并行区域，分配循环给区域内线程，每个线程执行一部分迭代。&#x3D;{red}for必须是传统格式的for(initialization; condition; increment)&#x3D;&#x3D;{red}只能是传统的计数器循环： 有符号的整形的递增&#x3D; 用法12345#pragma omp parallel for for (size_t i = 0; i &lt; vec.size(); i++) &#123; vec[i] *= 2; &#125; 原理 创建+分配+同步创建线程、迭代范围分配、结尾隐式屏障用于同步 创建线程团队：parallel 子句负责创建线程团队。 迭代分配：循环的迭代范围被分配给各个线程，每个线程独立完成自己的部分。 隐式屏障：循环结束时，所有线程在隐式屏障处同步，确保后续代码在所有线程完成任务后执行。 Command Rulex.1 变量共享规则 important关键在于哪些变量是共享的，哪些是线程私有的。 x.1.1 默认共享规则 在并行区域外定义变量默认为&#x3D;{red}共享变量(shared)&#x3D; 在并行区域内部声明的局部变量，自动私有化&#x3D;{red}私有变量(private)&#x3D; 共享&#x2F;私有变量共享变量所有线程都可见，私有变量只有本线程可见。 1234567891011121314151617181920212223242526272829// OpenMpTest.cpp : 此文件包含 &quot;main&quot; 函数。程序执行将在此处开始并结束。//#include &lt;iostream&gt;#include &lt;omp.h&gt;#include &lt;vector&gt;int main()&#123; int x = 0; std::vector&lt;std::pair&lt;decltype(&amp;x), decltype(&amp;x)&gt;&gt; result; #pragma omp parallel &#123; x = omp_get_thread_num(); int x_ = omp_get_thread_num(); // 保证在同一时间内只有一个线程可以访问这段代码。 #pragma omp critical &#123; result.push_back(&#123; &amp;x_, &amp;x &#125;); &#125; &#125; for (const auto&amp; p : result) &#123; // x的地址在所有线程都一致，x_的地址都不一样。 std::cout &lt;&lt; p.first &lt;&lt; &quot;, &quot; &lt;&lt; p.second &lt;&lt; std::endl; &#125; return 0;&#125; x.1.2 显式指定变量共享方式 default(xxx)：显式指定所有变量的共享方式。 default(shared)：变量共享。默认方式(存疑)。 default(none)：不指定共享方式，并行区域内的使用了外部变量，需要明确指定。 shared: 明确指定一个或多个变量是共享的。 一般用于于default(none)配合，用于明确指定变量共享方式12345678910111213141516171819202122232425262728int main()&#123; int x = -100; std::vector&lt;std::pair&lt;decltype(&amp;x), int&gt;&gt; result; const auto printfVector = [](const auto array_) &#123; std::cout &lt;&lt; &quot;vector : &quot; &lt;&lt; std::endl; for (const auto&amp; p : array_) &#123; std::cout &lt;&lt; p.first &lt;&lt; &quot;, &quot; &lt;&lt; p.second &lt;&lt; std::endl; &#125; std::cout &lt;&lt; &quot;----------------------&quot; &lt;&lt; std::endl; &#125;;// 不指定共享方式，需要显式指定共享方式#pragma omp parallel default(none) shared(x, result) &#123; x = omp_get_thread_num();#pragma omp critical &#123; result.push_back(&#123; &amp;x, x &#125;); &#125; &#125; printfVector(result); std::cout &lt;&lt; &amp;x &lt;&lt; &quot;: &quot; &lt;&lt; x &lt;&lt; std::endl; return 0;&#125; private: 明确指定一个或多个变量是私有的，每个线程拥有该变量的一个副本，原有变量的值不会被修改。 注意此时值是没有被初始化的，相当于生成了一个未初始化的副本x。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;iostream&gt;#include &lt;omp.h&gt;#include &lt;vector&gt;int main()&#123; int x = -100; std::vector&lt;std::pair&lt;decltype(&amp;x), int&gt;&gt; result; const auto printfVector = [](const auto array_) &#123; std::cout &lt;&lt; &quot;vector : &quot; &lt;&lt; std::endl; for (const auto&amp; p : array_) &#123; std::cout &lt;&lt; p.first &lt;&lt; &quot;, &quot; &lt;&lt; p.second &lt;&lt; std::endl; &#125; std::cout &lt;&lt; &quot;----------------------&quot; &lt;&lt; std::endl; &#125;;#pragma omp parallel private(x) &#123; x = omp_get_thread_num();#pragma omp critical &#123; result.push_back(&#123; &amp;x, x &#125;); &#125; &#125; printfVector(result); std::cout &lt;&lt; &amp;x &lt;&lt; &quot;: &quot; &lt;&lt; x &lt;&lt; std::endl; return 0;&#125;----- 输出vector :006FF900, 0007FF960, 10336FC68, 13025AFAA8, 20282F900, 40296F9C0, 502AAFA20, 602BEF860, 702D2F818, 802E6FE20, 902FAF880, 10030EFAA8, 110322F950, 12034AFBC0, 14026EFE48, 3035EFD20, 15----------------------006FFB40: -100 firstprivate: 明确指定一个变量的私有副本，并且该副本的初值是变量在并行区域外的值。 与private关键字的区别在于，有初始化，下边这段代码在vs2017会被警告变量未初始化。123456789101112131415int main()&#123; int x = -100; std::vector&lt;std::pair&lt;int, int&gt;&gt; result;#pragma omp parallel private(x) &#123; const auto tempX = x; x = omp_get_thread_num();#pragma omp critical &#123; result.push_back(&#123; tempX, x &#125;); &#125; &#125; return 0;&#125; 需要使用firstprivate关键字，用于初始化变量123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;algorithm&gt;#include &lt;iostream&gt;#include &lt;omp.h&gt;#include &lt;vector&gt;int main()&#123; int x = -100; std::vector&lt;std::pair&lt;int, int&gt;&gt; result;#pragma omp parallel firstprivate(x) &#123; const auto tempX = x; x = omp_get_thread_num();#pragma omp critical &#123; result.push_back(&#123; tempX, x &#125;); &#125; &#125; std::for_each(result.begin(), result.end(), [](const auto&amp; p) &#123; std::cout &lt;&lt; p.first &lt;&lt; &quot;, &quot; &lt;&lt; p.second &lt;&lt; std::endl; &#125;); return 0;&#125;----- 输出-100, 0-100, 10-100, 2-100, 1-100, 12-100, 4-100, 5-100, 6-100, 7-100, 8-100, 9-100, 11-100, 13-100, 14-100, 3-100, 15 lastprivate: 用于某些变量的私有副本，在并行区域结束后，将最后一个线程的私有副本的值复制回原始变量。 注意点：标识的变量必须是已经声明了，shared(xxx) x.2 临界区-避免数据竞争#pragma omp atomic 和 #pragma omp critical x.2.1 #pragma omp critical定义 定义临界区，在临界区内，某一时刻只允许一个线程执行代码用于定义一个临界区（critical section）。在这个区域内，某一时刻只允许一个线程执行代码，其它线程需要等待，直到当前线程退出临界区。 用法用于保护共享资源，提供同步机制，保证线程安全。 123456789101112131415161718192021#include &lt;algorithm&gt;#include &lt;iostream&gt;#include &lt;omp.h&gt;#include &lt;vector&gt;int main()&#123; int x = -100; std::vector&lt;std::pair&lt;int, int&gt;&gt; result;#pragma omp parallel firstprivate(x) &#123; const auto tempX = x; x = omp_get_thread_num();#pragma omp critical &#123; result.push_back(&#123; tempX, x &#125;); &#125; &#125; return 0;&#125; 原理通过加锁机制实现（如互斥锁），同一时间只能由一个线程访问该区域。需要锁开销，对于简单做法，可以选择atomic x.2.2 #pragma omp atomic定义 轻量级同步机制，用于对单个共享变量执行原子操作 操作必须针对单个变量 只能保护单条语句 用法123456789101112131415#include &lt;omp.h&gt;#include &lt;iostream&gt;int main() &#123; int sum = 0; #pragma omp parallel for for (int i = 0; i &lt; 10; i++) &#123; #pragma omp atomic sum += i; // 原子加法 &#125; std::cout &lt;&lt; &quot;Sum = &quot; &lt;&lt; sum &lt;&lt; std::endl; return 0;&#125; 原理#pragma omp atomic 通常通过硬件支持的原子指令（如 CAS：Compare and Swap）或低层次锁来实现。相比于 #pragma omp critical，它的开销更低，因为只保护单个变量，不需要进入临界区管理多线程资源。 x.3 归约操作x.3.1 reduction关键字定义 归约操作将多个数据项（不同线程计算单元）合并成单一结果，即正确合并线程对共享变量的修改 用法#pragma omp parallel for reduction(operator: variable)operator：用于归约的操作，用于归约的操作符，如 +、*、&amp; 等。variable：需要进行归约的变量 12345678910111213141516#include &lt;omp.h&gt;#include &lt;iostream&gt;int main() &#123; int arr[] = &#123;1, 2, 3, 4, 5&#125;; int sum = 0; #pragma omp parallel for reduction(+:sum) for (int i = 0; i &lt; 5; i++) &#123; sum += arr[i]; // 每个线程将自己计算的和存储到局部副本中 &#125; std::cout &lt;&lt; &quot;Sum = &quot; &lt;&lt; sum &lt;&lt; std::endl; // 输出最终的结果 return 0;&#125; 支持的操作符 加法 (+)：将所有线程的局部结果进行加法运算。 乘法 (*)：将所有线程的局部结果进行乘法运算。 按位与 (&amp;)：对所有线程的局部结果进行按位与运算。 按位或 (|)：对所有线程的局部结果进行按位或运算。 按位异或 (^)：对所有线程的局部结果进行按位异或运算。 逻辑与 (&amp;&amp;)：对所有线程的局部结果进行逻辑与运算。 逻辑或 (||)：对所有线程的局部结果进行逻辑或运算。 最小值 (min)：返回多个线程局部值中的最小值。 最大值 (max)：返回多个线程局部值中的最大值。 原理 局部副本：OpenMP 会为每个线程创建一个局部副本，线程在并行区域内对这个副本进行操作。 omp只会对reduction声明的变量创建局部副本。 根据规则会初始化每一个副本的初始值： 加法：副本初始值为0 乘法：副本初始值为1 逻辑运算&amp;&amp;：初始值为true 逻辑运算||：初始值为false 位操作&amp;：初始值位~0（即全1） 位操作|，位操作^：初始值0 原则：初始值不影响归约结果 如果变量已经有了一个初始值，则会将该初始值，参与到最后的归约操作中。如加法归约：initializer + sum_0 + sum_1 + … 合并操作并行区域结束后，OpenMP 会自动将各线程的局部结果合并，得到全局结果。 要点： important流程：创建局部副本-&gt;副本初始化-&gt;副本参与计算（因为是副本，所以没有竞争风险）-&gt;根据归约操作副本结果 归约操作只对声明变量负责，允许多个归约 自定义归约操作 declare reduction（MSVC不支持）定义指令 12#pragma omp declare reduction(identifier : type : combiner) \\ initializer(initializer_expression) **identifier**：归约操作符的名称。 **type**：应用于归约变量的类型。 **combiner**：定义如何将不同线程的私有副本合并到一起。 需要是表达式 omp_out: 归约变量，即最终结果变量 omp_in：当前线程归约变量，即操作变量 **initializer**：定义每个线程中归约变量的初始值。 表达式 omp_priv：表示线程私有归约变量 omp_orig：线程共享全局归约变量 用法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475class A&#123;public: A()&#123;&#125; A(int i) : a(i)&#123;&#125; int getA() const &#123; return a; &#125; void setA(int i) &#123; a = i; &#125; static void combine(A&amp; out, const A&amp; in) &#123; out.setA(out.getA() + in.getA()); &#125; private: int a = 0;&#125;; #pragma omp declare reduction(APluse : A : A::combine(omp_out, omp_in))\\ initializer(omp_priv = A(10)) void ompDecRefuction()&#123; A a(0);#pragma omp parallel for reduction(APluse : a) for(int i = 0; i &lt; 10; ++i) &#123; std::cout &lt;&lt; omp_get_num_threads() &lt;&lt; std::endl; a.setA(i + a.getA()); &#125; std::cout &lt;&lt; a.getA() &lt;&lt; std::endl;&#125; 手动自定义归约操作不支持自定义归约操作的编译器，可以考虑手动创建临界区进行归约操作。 12345678910111213141516void manualReduction()&#123; int global_sum = 0;#pragma omp parallel &#123; int local_sum = 0;#pragma omp for for (int i = 0; i &lt; 10; i++) &#123; local_sum += i; &#125;#pragma omp critical &#123; global_sum += local_sum; &#125; &#125; std::cout &lt;&lt; &quot;Sum: &quot; &lt;&lt; global_sum &lt;&lt; std::endl;&#125; X.4 其他线程操作-后缀x.4.1 nowait 跳过内存屏障 跳过parallel for，parallel sections默认的内存屏障。 不能用于omp parallel 主线程继续往下走，不等所有线程执行结束再往下执行1234#pragma omp parallel for reduction(+:sum) nowait for (int i = 0; i &lt; 5; i++) &#123; sum += arr[i]; // 每个线程将自己计算的和存储到局部副本中 &#125; x.4.2 num_threads(n)设置线程数量为n 线程的最大数量通常受硬件资源限制（如 CPU 核心数和内存大小）。 如果指定的线程数大于硬件核心数，线程调度开销可能会降低性能。1234#pragma omp parallel num_threads(4) // 局部设置线程数为 4 &#123; printf(&quot;Local: Thread %d\\n&quot;, omp_get_thread_num()); &#125; X.5 其他线程操作-函数调用x.5.1 omp_get_thread_num() 获取当前线程IDx.5.2 omp_get_num_threads() 获取当前并行区域的总线程数X.6 omp parallel和omp for结合原理当 #pragma omp parallel 和 #pragma omp for 嵌套使用时，for 循环的行为是 拆分任务，而不是重复调用。OpenMP 的工作原理是通过线程池并行执行代码，其中 #pragma omp parallel 创建线程组，而 #pragma omp for 则将循环迭代分配给这些线程。因此 12345678910111213#pragma omp parallel &#123;#pragma omp for for (int i = 0; i &lt; 10; i++) &#123; sum += i; &#125;------等同于#pragma omp parallel for for (int i = 0; i &lt; 10; i++) &#123; sum += i; &#125;","categories":[{"name":"OpenMP","slug":"OpenMP","permalink":"http://example.com/categories/OpenMP/"}],"tags":[]},{"title":"What is OpenMp","slug":"What-is-OpenMp","date":"2024-12-13T05:36:17.000Z","updated":"2024-12-13T07:18:01.247Z","comments":true,"path":"2024/12/13/What-is-OpenMp/","permalink":"http://example.com/2024/12/13/What-is-OpenMp/","excerpt":"","text":"OpenMp定义OpenMP 是一种用于共享内存和分布式共享内存多处理器的并行编程模型。基于共享内存并行系统的跨平台多线程设计方案。 关键词 共享内存：OpenMp假定每一个线程都能访问到相同的内存。 并行编程模型：OpenMp是一个并行编程模型，类似于C++一样的规范，需要各个厂商自己实现。 局限对于分布式内存计算平台，如超算中心，OpenMp不适用在多个不共享的内存之间进行运行，一般是结合MPI(Message Passing Interface)，多核心之间使用MPI进行通信，单核心之间使用OpenMp进行计算。 使用OpenMp的目的 加速计算，不为了加速，无需用OpenMp 优势减少并行计算开发的代价，提供简化方法，而无需关注的线程&#x2F;进程的管理和调用细节。 操作OPENMP使用指令（或称为编译指令、指示符）来指示编译器如何并行化程序中的部分代码。","categories":[{"name":"OpenMP","slug":"OpenMP","permalink":"http://example.com/categories/OpenMP/"}],"tags":[]}],"categories":[{"name":"OpenMP","slug":"OpenMP","permalink":"http://example.com/categories/OpenMP/"}],"tags":[]}